# üöÄ Confluent Cloud Infrastructure as Code

Este projeto implementa uma infraestrutura completa do Confluent Cloud na AWS usando Terraform, incluindo conectores para MySQL, DynamoDB e S3, com proxy NGINX para acesso via Private Link.

## üìã √çndice

- [Arquitetura](#-arquitetura)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [M√≥dulos](#-m√≥dulos)
- [Como Executar](#-como-executar)
- [Configura√ß√£o](#-configura√ß√£o)
- [Conectores](#-conectores)
- [Proxy NGINX](#-proxy-nginx)
- [Troubleshooting](#-troubleshooting)
- [Seguran√ßa](#-seguran√ßa)

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MySQL RDS     ‚îÇ    ‚îÇ  DynamoDB Table  ‚îÇ    ‚îÇ   S3 Bucket     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                  ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                       ‚îÇ
          ‚îÇ                      ‚îÇ                       ‚îÇ
          ‚ñº                      ‚ñº                       ‚ñ≤
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Confluent Cloud                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇMySQL Source ‚îÇ  ‚îÇDynamoDB Src ‚îÇ  ‚îÇ      Kafka Topic        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Connector   ‚îÇ  ‚îÇ Connector   ‚îÇ  ‚îÇ   topic-s3-sink-v2      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                  ‚îÇ              ‚îÇ
‚îÇ                                                  ‚ñº              ‚îÇ
‚îÇ                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ                                    ‚îÇ     S3 Sink Connector   ‚îÇ  ‚îÇ
‚îÇ                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ  NGINX Proxy    ‚îÇ
                          ‚îÇ  (EC2 Instance) ‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ   Your Local    ‚îÇ
                          ‚îÇ   Environment   ‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìã Pr√©-requisitos

### Software Necess√°rio
- [Terraform](https://www.terraform.io/downloads.html) >= 1.3
- Provider Confluent >= 2.32.0
- [AWS CLI](https://aws.amazon.com/cli/) configurado
- Conta no [Confluent Cloud](https://confluent.cloud/)
- Acesso SSH configurado

### Recursos AWS Existentes
- VPC com subnets privadas
- RDS MySQL (opcional)
- DynamoDB Table (opcional)
- S3 Bucket (opcional)

### Credenciais Necess√°rias
- **Confluent Cloud API Key/Secret** (Cloud API)
- **AWS Account ID** (via secret no GitHub Actions)
- **VPC ID e Subnet IDs**

## üß© M√≥dulos

### Core Modules

#### 1. **environment**
- **Prop√≥sito**: Cria o ambiente Confluent Cloud
- **Recursos**: `confluent_environment`
- **Outputs**: `environment_id`, `display_name`

#### 2. **kafka-cluster**
- **Prop√≥sito**: Provisiona cluster Kafka Enterprise
- **Recursos**: `confluent_kafka_cluster`
- **Tipos Suportados**: BASIC, STANDARD, ENTERPRISE, DEDICATED, FREIGHT
- **Outputs**: `cluster_id`, `bootstrap_endpoint`, `rest_endpoint`, `crn_pattern`

#### 3. **service-account**
- **Prop√≥sito**: Cria service account para conectores
- **Recursos**: `confluent_service_account`
- **Outputs**: `id`, `api_version`, `kind`

#### 4. **api-key**
- **Prop√≥sito**: Gera API keys para autentica√ß√£o Kafka
- **Recursos**: `confluent_api_key`
- **Outputs**: `kafka_api_key`, `kafka_api_secret` (sensitive)

#### 5. **role-binding**
- **Prop√≥sito**: Atribui permiss√µes ao service account
- **Recursos**: `confluent_role_binding`
- **Roles**: CloudClusterAdmin, DeveloperWrite
- **Outputs**: `role_binding_id`

### Networking Modules

#### 6. **private-link-attachment**
- **Prop√≥sito**: Cria Private Link Attachment
- **Recursos**: `confluent_private_link_attachment`
- **Clouds**: AWS, Azure, GCP
- **Outputs**: `id`, `dns_domain`, `aws`

#### 7. **aws-privatelink-endpoint**
- **Prop√≥sito**: Configura VPC Endpoint na AWS
- **Recursos**: `aws_vpc_endpoint`, `aws_route53_zone`, `aws_security_group`
- **Outputs**: `vpc_endpoint_id`

#### 8. **private-link-attachment-connection**
- **Prop√≥sito**: Conecta Private Link Attachment ao VPC Endpoint
- **Recursos**: `confluent_private_link_attachment_connection`
- **Outputs**: `id`, `display_name`

#### 9. **public-proxy** ‚≠ê
- **Prop√≥sito**: Proxy NGINX para acesso externo via Private Link
- **Recursos**: 
  - `aws_instance` (EC2)
  - `aws_security_group`
  - `aws_subnet`
  - `aws_route_table`
  - `tls_private_key` (SSH)
- **Peculiaridades**:
  - Configura NGINX com SNI routing
  - Gera chaves SSH automaticamente
  - Aguarda servi√ßos estarem prontos
  - Configura DNS automaticamente
- **Outputs**: `proxy_public_ip`, `ssh_command`, `diagnosis_command`

### Data Modules

#### 10. **kafka-topic**
- **Prop√≥sito**: Cria t√≥picos Kafka
- **Recursos**: `confluent_kafka_topic`
- **Configura√ß√µes**: retention, cleanup policy, partitions
- **Outputs**: `topic_name`, `topic_id`

#### 11. **kafka-connector**
- **Prop√≥sito**: M√≥dulo gen√©rico para conectores
- **Recursos**: `confluent_connector`
- **Tipos**: Source e Sink connectors
- **Outputs**: `connector_name`, `connector_id`

## üöÄ Como Executar

### 1. Clone o Reposit√≥rio
```bash
git clone https://github.com/santanadatatche/confluent-iac.git
cd confluent-iac/terraform/environments/evoluservices
```

### 2. Configure as Vari√°veis
Copie e edite o arquivo de vari√°veis:
```bash
cp terraform.tfvars.example terraform.tfvars
```

### 3. Configure Credenciais

**AWS:**
```bash
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
# Note: AWS region is automatically set to match Confluent region from terraform.tfvars
```

**Confluent Cloud:**
```bash
export CONFLUENT_CLOUD_API_KEY="your-confluent-api-key"
export CONFLUENT_CLOUD_API_SECRET="your-confluent-api-secret"
```

**‚ö†Ô∏è Importante**: Nunca coloque credenciais no arquivo terraform.tfvars. Use sempre vari√°veis de ambiente.

### 4. Inicialize o Terraform
```bash
terraform init
```

### 5. Planeje a Execu√ß√£o
```bash
terraform plan -var-file=terraform.tfvars
```

### 6. Execute a Infraestrutura
```bash
terraform apply -var-file=terraform.tfvars
```

### 7. Configure DNS (Importante!)
Ap√≥s a execu√ß√£o, execute o comando que aparece no output:
```bash
terraform output -raw hosts_command
# Execute o comando retornado
```

### 8. Destruir (quando necess√°rio)
```bash
terraform destroy -var-file=terraform.tfvars
```

## ‚öôÔ∏è Configura√ß√£o

### Arquivo terraform.tfvars

```hcl
# === GERAL ===
environment_name = "staging"
cloud            = "AWS"
region           = "us-east-2"

# === AWS === 
# aws_account_id ser√° fornecido via secret AWS_ACCOUNT_ID no GitHub Actions
aws_default_zones = [
    { "zone" = "us-east-2a", cidr = "172.30.1.0/16" },
    { "zone" = "us-east-2b", cidr = "172.30.2.0/16" },
    { "zone" = "us-east-2c", cidr = "172.30.3.0/16" }
]
aws_default_ami = "ami-0c55b159cbfafe1f0"

# === VPC ===
vpc_id = "vpc-xxxxxxxxx"
subnets_to_privatelink = {
  "use2-az1" = "subnet-xxxxxxxxx",
  "use2-az2" = "subnet-yyyyyyyyy",
  "use2-az3" = "subnet-zzzzzzzzz",
}

# === CLUSTER ===
cluster_name = "enterprise-aws-cluster"
cluster_type = "ENTERPRISE"
availability = "MULTI_ZONE"

# === TOPIC ===
topic_name = "topic-s3-sink-v2"
topic_partitions = 1
topic_config = {
  "cleanup.policy" = "delete"
  "retention.ms"   = "604800000"
}
```

## üöÄ Apache Flink

### Configura√ß√£o Private Link
O Flink est√° configurado para usar o mesmo Private Link Attachment do Kafka:

- **Endpoint Privado**: Configurado dinamicamente baseado na regi√£o
- **Endpoint P√∫blico**: Configurado dinamicamente baseado na regi√£o
- **Acesso**: Via proxy NGINX com SNI routing

### Como Acessar
```bash
# Via Private Link (ap√≥s configurar DNS)
curl -H "Authorization: Bearer <token>" https://$(terraform output -raw flink_private_endpoint)

# Verificar endpoint configurado
terraform output flink_private_endpoint
terraform output flink_public_endpoint
```

### Configura√ß√£o no Confluent Cloud
1. Acesse o Confluent Cloud Console
2. V√° para **Flink** > **Settings** > **Networking**
3. Configure o **Private Endpoint** para sua regi√£o configurada
4. Selecione o Private Link Attachment criado

## üîå Conectores

### MySQL CDC Source Connector
- **Classe**: `MySqlCdcSourceV2`
- **Formato**: JSON
- **Tabelas**: `kafkalab.customers`, `kafkalab.orders`
- **Prefixo**: `mysql`
- **Transforma√ß√µes**: ExtractNewRecordState

### DynamoDB CDC Source Connector
- **Classe**: `DynamoDbCdcSource`
- **Formato**: AVRO
- **Tabela**: `lab_table`
- **Prefixo**: `dynamodb`
- **Modo**: SNAPSHOT_CDC

### S3 Sink Connector
- **Classe**: `S3_SINK`
- **Formato**: JSON
- **Intervalo**: DAILY
- **Flush Size**: 1000
- **Toler√¢ncia a Erros**: ALL

## üåê Proxy NGINX

### Funcionalidades
- **SNI Routing**: Roteia tr√°fego baseado no Server Name Indication
- **Portas**: 443 (HTTPS) e 9092 (Kafka)
- **SSL Preread**: L√™ SNI sem descriptografar
- **Logs**: Stream routing logs detalhados
- **Flink Support**: Suporte ao Flink via Private Link

### Configura√ß√£o Autom√°tica
- Instala e configura NGINX automaticamente
- Gera chaves SSH para acesso
- Configura Security Groups
- Aguarda servi√ßos estarem prontos
- Testa conectividade das portas

### Acesso SSH
```bash
# Comando gerado automaticamente no output
ssh -i .ssh/terraform_aws_rsa ubuntu@<proxy-ip>
```

### Diagn√≥stico
```bash
# Comando gerado automaticamente no output
bash ../../scripts/diagnose_proxy.sh <proxy-ip> <cluster-hostname>
```

## üîç Troubleshooting

### Problemas Comuns

#### 1. DNS Resolution Failed
```bash
# Execute o comando de configura√ß√£o DNS
terraform output -raw hosts_command
# Execute o comando retornado
```

#### 2. Connector Failed
- Verifique logs no Confluent Cloud Console
- Confirme credenciais e permiss√µes
- Valide configura√ß√µes de rede

#### 3. Proxy Connection Issues
```bash
# Teste conectividade
nc -zv <proxy-ip> 443
nc -zv <proxy-ip> 9092

# Verifique logs do NGINX
ssh -i .ssh/terraform_aws_rsa ubuntu@<proxy-ip>
sudo tail -f /var/log/nginx/stream-error.log
```

#### 4. Permission Denied
- Verifique role bindings
- Confirme service account permissions
- Aguarde propaga√ß√£o de permiss√µes (30s)

### Logs Importantes
- **NGINX**: `/var/log/nginx/stream-*.log`
- **User Data**: `/var/log/user-data.log`
- **Confluent**: Console web do Confluent Cloud

## üîí Seguran√ßa e Melhores Pr√°ticas

### üîê Gerenciamento de Credenciais

#### Vari√°veis de Ambiente (Recomendado)
Este projeto foi configurado para usar vari√°veis de ambiente para todas as credenciais sens√≠veis:

```bash
# AWS Credentials
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
# Note: AWS region matches Confluent region from terraform.tfvars

# Confluent Cloud Credentials
export CONFLUENT_CLOUD_API_KEY="your-api-key"
export CONFLUENT_CLOUD_API_SECRET="your-api-secret"
```

#### ‚ùå O que N√ÉO fazer:
- Nunca coloque credenciais em arquivos `.tf` ou `.tfvars`
- N√£o commite credenciais no Git
- Evite hardcoding de secrets no c√≥digo
- N√£o compartilhe credenciais via chat/email

#### ‚úÖ O que fazer:
- Use vari√°veis de ambiente para credenciais
- Configure `.gitignore` para arquivos sens√≠veis
- Use ferramentas como AWS Secrets Manager em produ√ß√£o
- Implemente rota√ß√£o autom√°tica de credenciais

### üöÄ CI/CD e Automa√ß√£o

#### GitHub Actions
O projeto inclui workflow automatizado em `.github/workflows/deploy.yml`:

**Secrets necess√°rios no GitHub**:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_ACCOUNT_ID`
- `CONFLUENT_CLOUD_API_KEY`
- `CONFLUENT_CLOUD_API_SECRET`
- `MYSQL_PASSWORD`
- `CONNECTOR_AWS_ACCESS_KEY`
- `CONNECTOR_AWS_SECRET_KEY`
- `CONNECTOR_DYNAMODB_ACCESS_KEY`
- `CONNECTOR_DYNAMODB_SECRET_KEY`

**Comportamento**:
- **Pull Request**: Executa `terraform plan`
- **Push na main**: Executa `terraform apply`
- **Manual**: Via "Run workflow"

### üõ°Ô∏è Seguran√ßa de Rede

#### Private Link Security
- **Isolamento de Rede**: Tr√°fego nunca sai da AWS backbone
- **DNS Privado**: Resolu√ß√£o via Route53 private zones
- **Security Groups**: Acesso restrito por IP/CIDR
- **VPC Endpoints**: Comunica√ß√£o privada entre servi√ßos

#### Proxy Security
- **SNI Routing**: Inspe√ß√£o de certificados sem descriptografia
- **IP Whitelisting**: Acesso SSH apenas do IP p√∫blico atual
- **Chaves SSH**: Geradas automaticamente pelo Terraform
- **Logs Detalhados**: Monitoramento de todas as conex√µes

### üîë Controle de Acesso

#### Service Accounts
- **Service Accounts Espec√≠ficos**: Um por fun√ß√£o/ambiente
- **Roles Granulares**: Permiss√µes m√≠nimas necess√°rias
- **Scoped Access**: Limitado a recursos espec√≠ficos
- **Time-based Access**: Rota√ß√£o regular de credenciais

### üìä Monitoramento e Auditoria

#### Logs Importantes
```bash
# NGINX Proxy Logs
sudo tail -f /var/log/nginx/stream-access.log
sudo tail -f /var/log/nginx/stream-error.log

# AWS CloudTrail
aws logs describe-log-groups --log-group-name-prefix "/aws/"
```

### üìã Checklist de Seguran√ßa

#### Antes do Deploy
- [ ] Credenciais configuradas via vari√°veis de ambiente
- [ ] `.gitignore` configurado para arquivos sens√≠veis
- [ ] Security Groups com acesso m√≠nimo necess√°rio
- [ ] VPC e subnets adequadamente configuradas

#### Ap√≥s o Deploy
- [ ] Testar conectividade e funcionalidade
- [ ] Verificar logs de acesso e erros
- [ ] Confirmar que credenciais n√£o est√£o expostas
- [ ] Configurar monitoramento e alertas

#### Manuten√ß√£o Regular
- [ ] Rotacionar credenciais mensalmente
- [ ] Revisar logs de auditoria
- [ ] Atualizar depend√™ncias e providers
- [ ] Testar procedimentos de backup/restore

## üìä Outputs Importantes

```bash
# Informa√ß√µes do cluster
terraform output kafka_cluster_id
terraform output kafka_bootstrap_endpoint
terraform output kafka_rest_endpoint

# Informa√ß√µes do proxy
terraform output proxy_public_ip
terraform output proxy_ssh_command

# Comandos √∫teis
terraform output hosts_command
terraform output proxy_diagnosis_command

# Credenciais (sens√≠veis)
terraform output service_account_manager_api_key
terraform output service_account_manager_api_secret
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìö Refer√™ncias Oficiais

### Confluent Cloud Documentation
- [Service Accounts & API Keys](https://docs.confluent.io/cloud/current/security/authenticate/workload-identities/service-accounts/api-keys/overview.html#ccloud-api-keys)
- [Private Networking Overview](https://docs.confluent.io/cloud/current/networking/ccloud-console-access.html)
- [Console Access Networking](https://docs.confluent.io/cloud/current/networking/ccloud-console-access.html#ccloud-console-access-networking)
- [Flink Private Networking](https://docs.confluent.io/cloud/current/flink/operate-and-deploy/private-networking.html#flink-sql-enable-private-networking-pla)
- [AWS Private Link Service ID](https://docs.confluent.io/cloud/current/_images/aws-privatelink-service-id.png)

### Terraform Provider
- [Confluent Terraform Provider](https://registry.terraform.io/providers/confluentinc/confluent/latest)

### Connectors Documentation
- [MySQL CDC Source Connector v2](https://docs.confluent.io/cloud/current/connectors/cc-mysql-source-cdc-v2-debezium/cc-mysql-source-cdc-v2-debezium.html#cc-mysql-cdc-source-v2-debezium-custom-offsets)
- [DynamoDB CDC Source Connector](https://docs.confluent.io/cloud/current/connectors/cc-amazon-dynamodb-cdc-source.html?ajs_aid=ff022b43-854a-4110-af31-26220e3ee926&ajs_uid=4101400#configuration-properties)
- [AWS Networking for Connectors](https://docs.confluent.io/cloud/current/connectors/networking/aws-eap-1st-party.html)

### Project Repository
- [Datatche Confluent IAC](https://github.com/santanadatatche/confluent-iac)

## üìù Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

Copyright (c) 2025 **Datatche Inc**

---

**‚ö†Ô∏è Importante**: Este projeto cria recursos pagos no Confluent Cloud e AWS. Monitore os custos e destrua recursos quando n√£o necess√°rios.